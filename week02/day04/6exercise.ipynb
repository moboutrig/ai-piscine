{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Exercise 6 Grid Search\n",
    "\n",
    "The goal of this exercise is to learn how to make an exhaustive search over specified parameter values for an estimator. This is very useful because the hyperparameter which are the parameters of the model impact the performance of the model.\n",
    "\n",
    "The scikit learn object that runs the Grid Search is called GridSearchCV. We will learn tomorrow about the cross validation. For now, let us set the parameter **cv** to `[(np.arange(18576), np.arange(18576,20640))]`.\n",
    "This means that GridSearchCV splits the data set in a train and test set.\n",
    "\n",
    "Preliminary:\n",
    "\n",
    "- Load the California Housing data set. As precised, this time, there's no need to split the data set in train set and test set since GridSearchCV does it.\n",
    "\n",
    "You will have to run a Grid Search on the Random Forest on at least the hyperparameter that are mentioned below. It doesn't mean these are the only hyperparameter of the model. If possible, try at least 3 different values for each hyperparameter.\n",
    "\n",
    "1. Run a Grid Search with `n_jobs` set to `-1` to parallelize the computations on all CPUs. The hyperparameter to change are: n_estimators, max_depth, min_samples_leaf. It may take\n",
    "\n",
    "Now, let us analyse the grid search's results in order to select the best model.\n",
    "\n",
    "2. Write a function that takes as input the Grid Search object and that returns the best model **fitted**, the best set of hyperparameter and the associated score:\n",
    "\n",
    "    ```python\n",
    "    def select_model_verbose(gs):\n",
    "\n",
    "        return trained_model, best_params, best_score\n",
    "    ```\n",
    "\n",
    "3. Use the trained model to predict on a new point:\n",
    "\n",
    "```python\n",
    "new_point = np.array([[3.2031, 52., 5.47761194, 1.07960199, 910., 2.26368159, 37.85, -122.26]])\n",
    "```\n",
    "\n",
    "How do we know the best model returned by GridSearchCV is good enough and stable ? That is what we will learn tomorrow !\n",
    "\n",
    "**WARNING: Some combinations of hyper parameters are not possible. For example using the SVM, the kernel linear has no parameter gamma.**\n",
    "\n",
    "**Note**:\n",
    "\n",
    "- GridSearchCV can also take a Pipeline instead of a Machine Learning model. It is useful to combine some Imputers or Dimension reduction techniques with some Machine Learning models in the same Pipeline.\n",
    "- It may be useful to check on Kaggle if some Kagglers share their Grid Searches.\n",
    "\n",
    "Ressources:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "- https://stackoverflow.com/questions/38555650/try-multiple-estimator-in-one-grid-search\n",
    "\n",
    "\n",
    "- https://medium.com/fintechexplained/what-is-grid-search-c01fe886ef0a\n",
    "\n",
    "- https://elutins.medium.com/grid-searching-in-machine-learning-quick-explanation-and-python-implementation-550552200596\n",
    "\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6334b7743b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             'min_samples_leaf': [10,20,30]}\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m gridsearch = GridSearchCV(rf,\n\u001b[1;32m      7\u001b[0m                         \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 50, 75],\n",
    "            'max_depth':[3,5,7],\n",
    "            'min_samples_leaf': [10,20,30]}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "gridsearch = GridSearchCV(rf,\n",
    "                        parameters,\n",
    "                        cv = [(np.arange(18576), np.arange(18576,20640))],\n",
    "                        n_jobs=-1)\n",
    "gridsearch.fit(X, y)\n",
    "\n",
    "# 2.\n",
    "def select_model_verbose(gs):\n",
    "\n",
    "    return gs.best_estimator_, gs.best_params_, gs.best_score_\n",
    "\n",
    "# 3.\n",
    "model, best_params, best_score = select_model_verbose(gridsearch)\n",
    "model.predict(new_point)"
   ]
  }
 ]
}