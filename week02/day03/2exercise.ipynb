{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Exercise 2 Scaler\n",
    "\n",
    "The goal of this exercise is to learn to scale a data set. There are various scaling techniques, we will focus on `StandardScaler` from scikit learn.\n",
    "\n",
    "We will use a tiny data set for this exercise that we will generate by ourselves:\n",
    "\n",
    "```python\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                     [ 2.,  0.,  0.],\n",
    "                     [ 0.,  1., -1.]])\n",
    "```\n",
    "\n",
    "1. Fit the `StandardScaler` on the data and scale X_train using `fit_transform`. Compute the `mean` and `std` on `axis 0`.\n",
    "\n",
    "2. Scale the test set using the `StandardScaler` fitted on the train set. \n",
    "\n",
    "```python\n",
    "X_test = np.array([[ 2., -1.,  1.],\n",
    "                     [ 3.,  3.,  -1.],\n",
    "                     [ 1.,  1., 1.]])\n",
    "```\n",
    "\n",
    "**WARNING:\n",
    "If the data is split in train and test set, it is extremely important to apply the same scaling the the test data. As the model is trained on scaled data, if it takes as input unscaled data, it returns incorrect values.**\n",
    "\n",
    "Resources:\n",
    "\n",
    "- https://medium.com/technofunnel/what-when-why-feature-scaling-for-machine-learning-standard-minmax-scaler-49e64c510422\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/preprocessing.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.         -1.22474487  1.33630621]\n [ 1.22474487  0.         -0.26726124]\n [-1.22474487  1.22474487 -1.06904497]]\n[0. 0. 0.]\n[1. 1. 1.]\n[[ 1.22474487 -1.22474487  0.53452248]\n [ 2.44948974  3.67423461 -1.06904497]\n [ 0.          1.22474487  0.53452248]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                     [ 2.,  0.,  0.],\n",
    "                     [ 0.,  1., -1.]])\n",
    "\n",
    "# 1.\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_scaled = scaler.transform(X_train)\n",
    "print(X_scaled)\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))\n",
    "\n",
    "# 2.\n",
    "X_test = np.array([[ 2., -1.,  1.],\n",
    "                     [ 3.,  3.,  -1.],\n",
    "                     [ 1.,  1., 1.]])\n",
    "\n",
    "scaler_test = StandardScaler().fit(X_test)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_test_scaled)\n",
    "\n"
   ]
  }
 ]
}