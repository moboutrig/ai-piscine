{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Exercise 5 Breast Cancer prediction\n",
    "\n",
    "The goal of this exercise is to use Logistic Regression\n",
    "to predict breast cancer. It is always important to understand the data before training any Machine Learning algorithm. The data is described in **breast-cancer-wisconsin.names**. I suggest to add manually the column names in the DataFrame.\n",
    "\n",
    "Preliminary:\n",
    "\n",
    "- If needed, replace missing values with the median of the column.\n",
    "\n",
    "- Handle the column `Sample code number`. This column won't be used to train the model as it doesn't contain information on breast cancer. There are two solutions: drop it or set it as index.\n",
    "\n",
    "1. Print the proportion of class `Benign`.  What would be the accuracy if the model always predicts `Benign`?\n",
    "Later this week we will learn about other metrics as AUC that will help us to tackle high imbalanced data sets.\n",
    "\n",
    "2. Using train_test_split, split the data set in a train set and test set (20%). Both sets should should have approximately the same proportion of class `Benign`. Use `random_state = 43`.\n",
    "\n",
    "3. Fit the logistic regression on the train set. Predict on the train set and test set. Compute the score on the train set and test set. 92-97% accuracy is expected on the test set.\n",
    "\n",
    "4. Compute the confusion matrix on both tests. Analyse the number of false negative and false positive.\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "- https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Clump Thickness                 0\nUniformity of Cell Size         0\nUniformity of Cell Shape        0\nMarginal Adhesion               0\nSingle Epithelial Cell Size     0\nBare Nuclei                    16\nBland Chromatin                 0\nNormal Nucleoli                 0\nMitoses                         0\nClass                           0\ndtype: int64\n\nall good (removed): 0\nportion of class benign: 0.6552217453505007\nthis means that if we predict Benign your accuracy will be 66%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file = np.genfromtxt(\"breast-cancer-wisconsin.data\", delimiter=\",\")  \n",
    "\n",
    "# Attribute Information:\n",
    "# \n",
    "# 1. Sample code number: id number\n",
    "# 2. Clump Thickness: 1 - 10\n",
    "# 3. Uniformity of Cell Size: 1 - 10\n",
    "# 4. Uniformity of Cell Shape: 1 - 10\n",
    "# 5. Marginal Adhesion: 1 - 10\n",
    "# 6. Single Epithelial Cell Size: 1 - 10\n",
    "# 7. Bare Nuclei: 1 - 10\n",
    "# 8. Bland Chromatin: 1 - 10\n",
    "# 9. Normal Nucleoli: 1 - 10\n",
    "# 10. Mitoses: 1 - 10\n",
    "# 11. Class: (2 for benign, 4 for malignant)\n",
    "\n",
    "# we create a data frame with all the columns\n",
    "df = DataFrame(file, columns=['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class'])\n",
    "\n",
    "# remove the comlumns we do not need OR puting it as ID\n",
    "df = df.set_index('Sample code number')\n",
    "\n",
    "# replace the missinf values with the median of the column\n",
    "print(df.isnull().sum())\n",
    "df['Bare Nuclei'] = df['Bare Nuclei'].fillna(df['Bare Nuclei'].mean())\n",
    "print('\\nall good (removed):', df.isnull().sum().sum())\n",
    "\n",
    "# 1. portion on class Benign\n",
    "print('portion of class benign:', (df['Class'] == 2).sum()/len(df['Class']))\n",
    "print('this means that if we predict Benign your accuracy will be 66%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "portion of class benign test: 0.6571428571428571\nportion of class benign train: 0.6547406082289803\n"
     ]
    }
   ],
   "source": [
    "# 2.\n",
    "X, y = df.drop(['Class'], axis=1), df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=43, stratify=y)\n",
    "\n",
    "# testing\n",
    "print('portion of class benign test:', (y_test == 2).sum()/len(y_test))\n",
    "print('portion of class benign train:', (y_train == 2).sum()/len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predict: [4. 2. 4. 2. 2. 2. 2. 4. 2. 2.]\nprobability predict: [[4.65649710e-03 9.95343503e-01]\n [9.90960042e-01 9.03995849e-03]\n [7.05444060e-05 9.99929456e-01]\n [9.94699773e-01 5.30022688e-03]\n [9.79006762e-01 2.09932383e-02]\n [9.94168773e-01 5.83122708e-03]\n [9.63204039e-01 3.67959608e-02]\n [4.96441067e-03 9.95035589e-01]\n [9.92180521e-01 7.81947864e-03]\n [9.89521488e-01 1.04785115e-02]]\nscore: 0.9695885509838998\npredict: [2. 2. 2. 4. 2. 4. 2. 2. 2. 4.]\nprobability predict: [[9.82821870e-01 1.71781299e-02]\n [7.83881983e-01 2.16118017e-01]\n [9.93012989e-01 6.98701126e-03]\n [2.17405344e-01 7.82594656e-01]\n [9.98443347e-01 1.55665329e-03]\n [1.59078715e-03 9.98409213e-01]\n [6.60767146e-01 3.39232854e-01]\n [9.87891047e-01 1.21089534e-02]\n [9.95641306e-01 4.35869376e-03]\n [2.89811233e-04 9.99710189e-01]]\nscore: 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "# 3.\n",
    "# X_train = X_train.to_numpy().reshape(-1, 1)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "# Train\n",
    "predict = clf.predict(X_train)\n",
    "print('predict:', predict[:10])\n",
    "\n",
    "prob_predict = clf.predict_proba(X_train)\n",
    "print('probability predict:', prob_predict[:10])\n",
    "\n",
    "print('score:', clf.score(X_train, y_train))\n",
    "\n",
    "# Test\n",
    "predict_test = clf.predict(X_test)\n",
    "print('predict:', predict_test[:10])\n",
    "\n",
    "prob_predict = clf.predict_proba(X_test)\n",
    "print('probability predict:', prob_predict[:10])\n",
    "\n",
    "print('score:', clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[357   9]\n [  8 185]]\n[[90  2]\n [ 3 45]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Compute the confusion matrix on both tests. Analyse the number of false negative and false positive.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# calculates the loss\n",
    "# train predict: [4. 2. 4. 2. 2. 2. 2. 4. 2. 2.]\n",
    "# test predict: [2. 2. 2. 4. 2. 4. 2. 2. 2. 4.]\n",
    "\n",
    "confusion_test = confusion_matrix(y_test, predict_test)\n",
    "confusion_train = confusion_matrix(y_train, predict)\n",
    "print(confusion_train)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}