{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Exercise 3 GridsearchCV\n",
    "\n",
    "The goal of this exercise is to learn to use GridSearchCV to run a grid search, predict on the test set and score on the test set.\n",
    "\n",
    "Preliminary:\n",
    "\n",
    "- Import California Housing data set and split it in a train set and a test set (10%). Fit a linear regression on the data set. *The goal is to focus on the gridsearch, that is why the code to fit the Linear Regression is given.*\n",
    "\n",
    "```python\n",
    "#imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "#split data train test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "#pipeline \n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "pipe = Pipeline(pipeline)\n",
    "```\n",
    "\n",
    "1. Run `GridSearchCV` on all CPUs with 5 folds, MSE as score, Random Forest as model with:\n",
    "\n",
    "- max_depth between 1 and 20 (at least 3 values)\n",
    "- n_estimators between 1 and 100 (at least 3 values)\n",
    "\n",
    "This may take few minutes to run.\n",
    "\n",
    "*Hint*: The name of the metric to put in the parameter `scoring` is `neg_mean_squared_error`. The smaller the MSE is, the better the model is. At the contrary, The greater the R2 is the better the model is. `GridSearchCV` chooses the best model by selecting the one that maximized the score on the validation sets. And, in mathetmatic, maximzing a function or minimzing its opposite is equivalent. More details:\n",
    "\n",
    "- https://stackoverflow.com/questions/21443865/scikit-learn-cross-validation-negative-values-with-mean-squared-error\n",
    "\n",
    "2. Extract the best fitted estimator, print its params, print its score on the validation set and print `cv_results_`.\n",
    "\n",
    "3. Compute the score the test set.\n",
    "\n",
    "**WARNING: If the score used in classification is the AUC, there is one rare case where the AUC may return an error or a warning: The fold contains only one class. In that case it can't be computed, by definition.**\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.29155187671448063\n{'max_depth': 10, 'n_estimators': 75}\n{'mean_fit_time': array([0.49330783, 2.17938128, 3.37942586, 0.73762355, 3.60652013,\n       6.02801886, 1.01369634, 6.42465711, 7.83597479]), 'std_fit_time': array([0.03276028, 0.11588314, 0.13233421, 0.08189721, 0.16334649,\n       0.36806859, 0.06414597, 0.2397275 , 0.89071465]), 'mean_score_time': array([0.00608697, 0.01854568, 0.02624226, 0.00551362, 0.02538805,\n       0.04687972, 0.00957913, 0.04579592, 0.04288216]), 'std_score_time': array([0.00275626, 0.00130466, 0.00322864, 0.00062858, 0.0032865 ,\n       0.00594217, 0.00294153, 0.01430291, 0.00872202]), 'param_max_depth': masked_array(data=[4, 4, 4, 7, 7, 7, 10, 10, 10],\n             mask=[False, False, False, False, False, False, False, False,\n                   False],\n       fill_value='?',\n            dtype=object), 'param_n_estimators': masked_array(data=[10, 50, 75, 10, 50, 75, 10, 50, 75],\n             mask=[False, False, False, False, False, False, False, False,\n                   False],\n       fill_value='?',\n            dtype=object), 'params': [{'max_depth': 4, 'n_estimators': 10}, {'max_depth': 4, 'n_estimators': 50}, {'max_depth': 4, 'n_estimators': 75}, {'max_depth': 7, 'n_estimators': 10}, {'max_depth': 7, 'n_estimators': 50}, {'max_depth': 7, 'n_estimators': 75}, {'max_depth': 10, 'n_estimators': 10}, {'max_depth': 10, 'n_estimators': 50}, {'max_depth': 10, 'n_estimators': 75}], 'split0_test_score': array([-0.4919316 , -0.48777943, -0.48661455, -0.34127241, -0.33490113,\n       -0.33312593, -0.28010797, -0.26118169, -0.2615094 ]), 'split1_test_score': array([-0.52920977, -0.52474326, -0.52762593, -0.38123806, -0.37209396,\n       -0.36783188, -0.3021608 , -0.28648192, -0.2870785 ]), 'split2_test_score': array([-0.5301379 , -0.52368392, -0.52109104, -0.3836942 , -0.37850238,\n       -0.37969163, -0.31231395, -0.3020977 , -0.29788875]), 'split3_test_score': array([-0.5160395 , -0.50916265, -0.50917436, -0.38436696, -0.37535554,\n       -0.37596479, -0.31718405, -0.30641456, -0.30521647]), 'split4_test_score': array([-0.53920734, -0.52995876, -0.52873271, -0.38285244, -0.3808004 ,\n       -0.37526274, -0.31587838, -0.30375281, -0.30606627]), 'mean_test_score': array([-0.52130522, -0.5150656 , -0.51464772, -0.37468481, -0.36833068,\n       -0.3663754 , -0.30552903, -0.29198574, -0.29155188]), 'std_test_score': array([0.01644093, 0.0152913 , 0.01564707, 0.01673892, 0.01697058,\n       0.01706407, 0.01375906, 0.01690023, 0.01649307]), 'rank_test_score': array([9, 8, 7, 6, 5, 4, 3, 2, 1], dtype=int32)}\n-----------\n-0.2731054693440584\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "#split data train test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "#pipeline \n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "pipe = Pipeline(pipeline)\n",
    "\n",
    "# 1.\n",
    "parameters = {'n_estimators':[10, 50, 75],\n",
    "            'max_depth':[4, 7, 10]}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "gridsearch = GridSearchCV(rf,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs=-1,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# 2.\n",
    "print(gridsearch.best_score_)\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.cv_results_)\n",
    "\n",
    "# The best score is -0.29028202683007526, that means that the MSE is ~0.29, it doesn't give any information since this metric is arbitrary. This score is the average of `neg_mean_squared_error` on all the validation sets.\n",
    "\n",
    "# 3.\n",
    "print('-----------')\n",
    "print(gridsearch.score(X_test, y_test))\n",
    "# The MSE score is ~0.27. The score I got on the test set is close to the score I got on the validation sets. It means the models is not over fitted."
   ]
  }
 ]
}