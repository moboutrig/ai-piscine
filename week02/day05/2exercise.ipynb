{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise 2: Cross validation (k-fold)\n",
    "\n",
    "The goal of this exercise is to learn how to use cross validation. After reading the articles you should be able to explain why we need to cross-validate the models. We will firstly focus on Linear Regression to reduce the computation time. We will be using `cross_validate` to run the cross validation. Note that `cross_val_score` is similar bu the `cross_validate` calculates one or more scores and timings for each CV split.\n",
    "\n",
    "Preliminary:\n",
    "\n",
    "- Import California Housing data set and split it in a train set and a test set (10%). Fit a linear regression on the data set. *The goal is to focus on the cross validation, that is why the code to fit the Linear Regression is given.*\n",
    "\n",
    "```python\n",
    "#imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "#split data train test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "#pipeline \n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "pipe = Pipeline(pipeline)\n",
    "```\n",
    "\n",
    "1. Cross validate the Pipeline using `cross_validate` with 10 folds. Print the scores on each validation sets, the mean score on the validation sets and the standard deviation on the validation sets. The expected output is:\n",
    "\n",
    "```console\n",
    "Scores on validation sets: \n",
    " [0.62433594 0.61648956 0.62486602 0.59891024 0.59284295 0.61307055\n",
    " 0.54630341 0.60742976 0.60014575 0.59574508]\n",
    "\n",
    "Mean of scores on validation sets: \n",
    " 0.60201392526743\n",
    "\n",
    "Standard deviation of scores on validation sets: \n",
    " 0.0214983822773466\n",
    "\n",
    " ```\n",
    "\n",
    "**Note: It may be confusing that the key of the dictionary that returns the results on the validation sets is `test_score`. Sometimes, the validation sets are called test sets. In that case, we run the cross validation on X_train. It means that the scores are computed on sets in the initial train set. The X_test is not used for the cross-validation.**\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "\n",
    "- https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "scores on valudation sets:\n [0.62433594 0.61648956 0.62486602 0.59891024 0.59284295 0.61307055\n 0.54630341 0.60742976 0.60014575 0.59574508]\n\nmean of scores on validation sets:\n 0.6020139252674299\n\nstandard deviation of scores on validation sets: 0.02149838227734665\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "#split data train test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "#pipeline \n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "pipe = Pipeline(pipeline)\n",
    "\n",
    "# 1.\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html\n",
    "scores = cross_validate(pipe, X_train, y_train, cv=10, scoring=('r2'), return_train_score=True)\n",
    "\n",
    "print('scores on valudation sets:\\n', scores['test_score'])\n",
    "print('\\nmean of scores on validation sets:\\n', scores['test_score'].mean())\n",
    "\n",
    "print('\\nstandard deviation of scores on validation sets:', scores['test_score'].std())"
   ]
  }
 ]
}