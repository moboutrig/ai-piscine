{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Exercise 5 Regression\n",
    "\n",
    "The goal of this exercise is to learn to adapt the output layer to regression.\n",
    "\n",
    "As a reminder, one of reasons for which the sigmoid is used in classification is because it contracts the output between 0 and 1 which is the expected output range for a probability (W2D2: Logistic regression). However, the output of the regression is not a probability.\n",
    "\n",
    "In order to perform a regression using a neural network, the activation function of the neuron on the output layer has to be modified to **identity function**. In mathematics, the identity function is: **`f(x) = x`**. In other words it means that it returns the input as so. The three steps become:\n",
    "\n",
    "1. Each input is multiplied by a weight\n",
    "    - `x1 -> x1 * w1`\n",
    "    - `x2 -> x2 * w2`\n",
    "\n",
    "2. The weighted inputs are added together with a biais `b`\n",
    "    - `(x1 * w1) + (x2 * w2) + b`\n",
    "\n",
    "3. The sum is passed through an activation function\n",
    "    - `y = f((x1 * w1) + (x2 * w2) + b)`\n",
    "    - The activation function is **the identity**\n",
    "    - `y = (x1 * w1) + (x2 * w2) + b`\n",
    "\n",
    "All other neurons' activation function **doesn't change**.\n",
    "\n",
    "1. Adapt the neuron class implemented in exercise 1. It now takes as a parameter `regression` which is boolean. When its value is `True`, `feedforward` should use the identity function as activation function instead of the sigmoid function.\n",
    "\n",
    "```python\n",
    "class Neuron:\n",
    "def __init__(self, weight1, weight2, bias, regression):\n",
    "    self.weights_1 = weight1\n",
    "    self.weights_2 = weight2\n",
    "    self.bias = bias\n",
    "    #TODO\n",
    "\n",
    "def feedforward(self, x1, x2):\n",
    "    #TODO\n",
    "    return y\n",
    "```\n",
    "\n",
    "- Compute the output for:\n",
    "\n",
    "```python\n",
    "neuron = Neuron(0,1,4, True)\n",
    "neuron.feedforward(2,3)\n",
    "```\n",
    "\n",
    "2. Now, the goal of the network is to predict the physics' grade at the exam given math and chemistry grades. The inputs are `math` and `chemistry` and the target is `physics`.\n",
    "\n",
    "| name   |   math |   chemistry |   physics |\n",
    "|:-------|-------:|------------:|---------------:|\n",
    "| Bob    |     12 |          15 |              16 |\n",
    "| Eli    |     10 |           9 |              10 |\n",
    "| Tom    |     18 |          18 |              19 |\n",
    "| Ryan   |     13 |          14 |              16 |\n",
    "\n",
    "Compute and return the output of the neural network for each of the students. Here are the weights and biases of the neural network:\n",
    "\n",
    "```python\n",
    "#replace regression by the right value\n",
    "neuron_h1 = Neuron(0.05, 0.001, 0, regression)\n",
    "neuron_h2 = Neuron(0.002, 0.003, 0, regression)\n",
    "neuron_o1 = Neuron(2,7,10, regression)\n",
    "```\n",
    "\n",
    "3. Compute the MSE for the 4 students.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 1.\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias, regression):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.regression = regression\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        x = np.dot(self.weights, inputs) + self.bias\n",
    "        if self.regression:\n",
    "            # identity function: f(x) = x\n",
    "            return x\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "neuron = Neuron(np.array([0,1]),4, True)\n",
    "out = neuron.feedforward(np.array([2,3]))\n",
    "\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bob: 14.918863163724454\nEli: 14.83137890625537\nTom: 15.086662606964074\nRyan: 14.939270885974128\n---------------\n"
     ]
    }
   ],
   "source": [
    "# 2.\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, neuron_h1, neuron_h2, neuron_o1):\n",
    "        self.h1 = neuron_h1\n",
    "        self.h2 = neuron_h2\n",
    "        self.o1 = neuron_o1\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        out_h1 = self.h1.feedforward(inputs)\n",
    "        out_h2 = self.h2.feedforward(inputs)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "\n",
    "neuron_h1 = Neuron(np.array([0.05, 0.001]), 0, False)\n",
    "neuron_h2 = Neuron(np.array([0.002, 0.003]), 0, False)\n",
    "neuron_o1 = Neuron(np.array([2, 7]), 10, True)\n",
    "\n",
    "neural_network = NeuralNetwork(neuron_h1, neuron_h2, neuron_o1)\n",
    "\n",
    "# we now that the input will be the math and the chemistry notes\n",
    "# and the prediction will be the physics notes\n",
    "Bob_pred = neural_network.feedforward(np.array([12, 15]))\n",
    "Eli_pred = neural_network.feedforward(np.array([10, 9]))\n",
    "Tom_pred = neural_network.feedforward(np.array([18, 18]))\n",
    "Ryan_pred = neural_network.feedforward(np.array([13, 14]))\n",
    "\n",
    "print('Bob:', Bob_pred)\n",
    "print('Eli:', Eli_pred)\n",
    "print('Tom:', Tom_pred)\n",
    "print('Ryan:', Ryan_pred)\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 0 1 1]\n[11.713 11.347 12.466 11.804]\n8.63489399808522\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array([1, 0, 1, 1])#16.0, 10.0, 19.0, 16.0])\n",
    "y_pred = np.array([Bob_pred, Eli_pred, Tom_pred, Ryan_pred])\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  }
 ]
}