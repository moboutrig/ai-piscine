{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Exercise 4 Optimize\n",
    "\n",
    "The goal of this exercise is to learn to train the neural network. Once the architecture of the neural network is set there are two steps to train the neural network:\n",
    "\n",
    "- `compile`:  The compilation step aims to set the loss function, to choose the algoithm to minimize the chosen loss function and to choose the metric the model outputs.\n",
    "\n",
    "- The **optimizer**. We’ll stick with a pretty good default: the Adam gradient-based optimizer. Keras has many other optimizers you can look into as well.\n",
    "\n",
    "- The **loss function**. Depending on the problem to solve: classification or regression Keras proposes different loss functions. In classification Keras distinguishes between `binary_crossentropy` (2 classes) and `categorical_crossentropy` (>2 classes), so we’ll use the latter.\n",
    "\n",
    "- The **metric(s)**. A list of metrics. Depending on the problem to solve: classification or regression Keras proposes different loss functions. For example for classification the metric can be the accuracy.\n",
    "\n",
    "- `fit`: Training a model in Keras literally consists only of calling fit() and specifying some parameters. There are a lot of possible parameters, but we’ll only manually supply a few:\n",
    "\n",
    "  - The **training data**, commonly known as X and Y, respectively.\n",
    "  - The **number of epochs** (iterations over the entire dataset) to train for.\n",
    "  - The **batch size** (number of samples per gradient update) to use when training.\n",
    "\n",
    "This article gives more details about **epoch** and **batch size**:\n",
    "\n",
    "- https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "\n",
    "1. Create the following neural network (classification):\n",
    "\n",
    "- Set the right number of inputs variables\n",
    "- hidden layer 1: 10 neurons and sigmoid as activation function.\n",
    "- hidden layer 2: 5 neurons and sigmoid as activation function.\n",
    "- output layer: 1 neuron and sigmoid as activation function.\n",
    "- Choose the accuracy metric, the adam optimizer, the adapted loss and epoch smaller than 50.\n",
    "\n",
    "Import the breast cancer data set from `sklearn.datasets` using `load_breast_cancer` and train the neural network on the data set.  \n",
    "\n",
    "2. Scale the data using `StandardScaler` from `sklearn.preprocessing`. Train the neural network again.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.3283\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.3556\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.3618\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.3712\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.3780\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5162\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5440\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5719\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5831\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.6009\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6204\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6070\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.6148\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.6181\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6137\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.6104\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6215\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.6115\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6115\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6048\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6215\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.6137\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.6104\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6048\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6170\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6137\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.6081\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.6126\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.6037\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6104\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6126\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6137\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6104\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6148\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.6181\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.6126\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6115\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6170\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6093\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6059\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6081\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6004\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.6104\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6115\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.6126\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6159\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6204\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.6104\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.6104\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.6170\n",
      "[{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 30), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'dense_33_input'}}, {'class_name': 'Dense', 'config': {'name': 'dense_33', 'trainable': True, 'batch_input_shape': (None, 30), 'dtype': 'float32', 'units': 10, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_34', 'trainable': True, 'dtype': 'float32', 'units': 5, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_35', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1.\n",
    "# get the data_set\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# load the target and the data\n",
    "y, X = data.target, data.data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=43)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# set neurons, all layers (hidden and output)\n",
    "model.add(Dense(10, input_dim=30, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "fit the data in the model, trining the model in Keras literally consists only\n",
    "of calling fit() and specifuing some parameters\n",
    "\n",
    "- The **training data**, commonly known as X and Y, respectively.\n",
    "- The **number of epochs** (iterations over the entire dataset) to train for.\n",
    "- The **batch size** (number of samples per gradient update) to use when training.\n",
    "'''\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=300)\n",
    "\n",
    "# testing\n",
    "print(model.get_config()['layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[9.405e+00 2.170e+01 5.960e+01 ... 3.770e-02 2.872e-01 8.304e-02]\n",
      " [1.132e+01 2.708e+01 7.176e+01 ... 2.083e-02 2.849e-01 7.087e-02]\n",
      " [1.369e+01 1.607e+01 8.784e+01 ... 6.987e-02 3.323e-01 7.701e-02]\n",
      " ...\n",
      " [1.881e+01 1.998e+01 1.209e+02 ... 1.294e-01 2.567e-01 5.737e-02]\n",
      " [1.396e+01 1.705e+01 9.143e+01 ... 1.374e-01 3.068e-01 7.957e-02]\n",
      " [1.025e+01 1.618e+01 6.652e+01 ... 9.744e-02 2.608e-01 9.702e-02]]\n",
      "[[-1.32109803  0.55900829 -1.31064248 ... -1.16561925 -0.0635106\n",
      "  -0.07183175]\n",
      " [-0.78952224  1.7885245  -0.82230376 ... -1.4144706  -0.10101389\n",
      "  -0.7457593 ]\n",
      " [-0.13164516 -0.72764157 -0.17654006 ... -0.69107582  0.67188003\n",
      "  -0.40574984]\n",
      " ...\n",
      " [ 1.2895914   0.16592876  1.15113082 ...  0.18705817 -0.56083686\n",
      "  -1.49333712]\n",
      " [-0.05669714 -0.50367765 -0.0323677  ...  0.30506711  0.25608267\n",
      "  -0.26398694]\n",
      " [-1.08653848 -0.70250276 -1.03273919 ... -0.28438753 -0.49398316\n",
      "   0.70232661]]\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6106\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.6106\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6106\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.6106\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6106\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6106\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6489 - accuracy: 0.6106\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6106\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6106\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6106\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6106\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6276 - accuracy: 0.6106\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6106\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6106\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6106\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6106\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6106\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6106\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.6106\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6106\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6131\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5876 - accuracy: 0.6156\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.6181\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6256\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.6256\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.6281\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.6432\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.6558\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.6683\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.6884\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5549 - accuracy: 0.7010\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7085\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7186\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7312\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.7437\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.7588\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7638\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5309 - accuracy: 0.7739\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7839\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7940\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7965\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.8015\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.8116\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.8216\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.8241\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.8317\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.8367\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8417\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.8467\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.8492\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f785c6376a0>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train, y_train)\n",
    "print(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "print(X_train_transformed)\n",
    "\n",
    "model.fit(X_train_transformed, y_train, epochs=50, batch_size=300)"
   ]
  }
 ]
}